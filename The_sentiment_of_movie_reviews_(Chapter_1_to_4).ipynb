{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY_z1w4Qpcgd"
      },
      "outputs": [],
      "source": [
        "#install packages\n",
        "!pip install transformers accelerate datasets tqdm openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "from sklearn.metrics import classification_report\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "OCvN5S1mpqM6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The sentiment of movie reviews.**"
      ],
      "metadata": {
        "id": "VXL_gd8bqB3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "data = load_dataset(\"rotten_tomatoes\")"
      ],
      "metadata": {
        "id": "GBFeGxI9pqIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representation models"
      ],
      "metadata": {
        "id": "h2Gsi1c5qwmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Task specific model"
      ],
      "metadata": {
        "id": "DoblNXPsq-Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model selection\n",
        "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "#build the model\n",
        "generator = pipeline(model=model_path, tokenizer=model_path, return_all_scores=True, device=\"cuda:0\")\n",
        "\n",
        "#y_predicted data\n",
        "y_pred = []\n",
        "\n",
        "#predict\n",
        "for output in tqdm(generator(KeyDataset(data['test'], 'text')), total=len(data['test'])):\n",
        "  negative_scores = output[0]['score']\n",
        "  positive_scores = output[2]['score']\n",
        "  assignment = np.argmax([negative_scores, positive_scores])\n",
        "  y_pred.append(assignment)"
      ],
      "metadata": {
        "id": "PjuGPJunpqDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation function\n",
        "def evaluation(y_true, y_pred):\n",
        "  report = classification_report(y_true, y_pred)\n",
        "  return report"
      ],
      "metadata": {
        "id": "uXuonimhtXiC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = evaluation(data['test']['label'], y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "nwZ-aJRNtlzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Embaddings model"
      ],
      "metadata": {
        "id": "YXafgyd3t1Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "3RNa-Uuit0nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "_n1hLeUouEmu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_model_path = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "emb_model = SentenceTransformer(emb_model_path)\n",
        "\n",
        "train_embadings = emb_model.encode(data['train']['text'], show_progress_bar=True)\n",
        "\n",
        "test_embadings = emb_model.encode(data['test']['text'], show_progress_bar=True)"
      ],
      "metadata": {
        "id": "tOrogd9LuJPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Logistic Regression Model\n",
        "clf_model = LogisticRegression()\n",
        "\n",
        "#Fit the model\n",
        "clf_model.fit(train_embadings, data['train']['label'])\n",
        "\n",
        "#predict\n",
        "clf_y_pred = clf_model.predict(test_embadings)\n",
        "\n",
        "#evaluation\n",
        "report = evaluation(data['test']['label'], clf_y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "KlqE2q0Ou_wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What if we do not have labeled data?"
      ],
      "metadata": {
        "id": "vWXglmfzw7R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_embadings = emb_model.encode([\"A very negative movie review\", \"A positive movie review\"])"
      ],
      "metadata": {
        "id": "paQDTXzwxJvl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "ZOOkOak8xvAt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_matrix = cosine_similarity(test_embadings, label_embadings)\n",
        "cos_y_pred = np.argmax(sim_matrix, axis=1)"
      ],
      "metadata": {
        "id": "8E9sKrF70ck6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = evaluation(data['test']['label'], cos_y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "JeA2xUbr1leY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative models"
      ],
      "metadata": {
        "id": "wJSMwwIp128F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Flan-T5\n"
      ],
      "metadata": {
        "id": "1GALC_645_BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text2text-generation\",model=\"google/flan-t5-small\",device=\"cuda:0\")"
      ],
      "metadata": {
        "id": "cKCxtKJzBRxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Is the following sentence positive or negative? \"\n",
        "data = data.map(lambda example: {\"t5\": prompt + example['text']})\n",
        "data"
      ],
      "metadata": {
        "id": "vk94MlSABU_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"t5\")),total=len(data[\"test\"])):\n",
        "  text = output[0][\"generated_text\"]\n",
        "  y_pred.append(0 if text == \"negative\" else 1)"
      ],
      "metadata": {
        "id": "jt73QpOrBccC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "Ms2CJBMQBiwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Gpt-3.5-turbo"
      ],
      "metadata": {
        "id": "bX10HB5VCOlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "3nBsu9yYCWL5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(api_key=\"Your openai key\")"
      ],
      "metadata": {
        "id": "TzVduZr-1Gle"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatgpt_generation(prompt, document, model=\"gpt-3.5-turbo-0125\"):\n",
        "  messages=[{\"role\": \"system\",\"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\",\"content\": prompt.replace(\"[DOCUMENT]\", document)}\n",
        "            ]\n",
        "  chat_completion = client.chat.completions.create(messages=messages,\n",
        "                                                   model=model,\n",
        "                                                   temperature=0)\n",
        "\n",
        "  return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "uSxPKzF51jYO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Predict whether the following document is a positive\n",
        "or negative movie review:\n",
        "[DOCUMENT]\n",
        "If it is positive return 1 and if it is negative return 0. Do not\n",
        "give any other answers.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "U375DocY2eLx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [chatgpt_generation(prompt, doc) for doc in tqdm(data[\"test\"][\"text\"])]\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "for output in predictions:\n",
        "  if len(output) > 1:\n",
        "    output = '1'\n",
        "  y_pred.append(int(output))"
      ],
      "metadata": {
        "id": "89ivAlru2kzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "LT62rQDk2oSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}